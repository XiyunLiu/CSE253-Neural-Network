{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import struct\n",
    "from array import array\n",
    "\n",
    "\n",
    "class MNIST(object):\n",
    "    def __init__(self, path='../HW1/dataset'):\n",
    "        self.path = path\n",
    "\n",
    "        self.test_img_fname = 't10k-images-idx3-ubyte'\n",
    "        self.test_lbl_fname = 't10k-labels-idx1-ubyte'\n",
    "\n",
    "        self.train_img_fname = 'train-images-idx3-ubyte'\n",
    "        self.train_lbl_fname = 'train-labels-idx1-ubyte'\n",
    "\n",
    "        self.test_images = []\n",
    "        self.test_labels = []\n",
    "\n",
    "        self.train_images = []\n",
    "        self.train_labels = []\n",
    "\n",
    "    def load_testing(self):\n",
    "        ims, labels = self.load(os.path.join(self.path, self.test_img_fname),\n",
    "                                os.path.join(self.path, self.test_lbl_fname))\n",
    "        ims = map(lambda img: img, ims)\n",
    "        self.test_images = ims\n",
    "        self.test_labels = labels\n",
    "        ims = map(lambda img: [1]+img, ims)\n",
    "        ims = np.array(ims)*1.0/255\n",
    "        mean = ims.sum(axis=1)[:,None]/785\n",
    "        ims -= mean\n",
    "        return ims, np.array(labels)\n",
    "\n",
    "    def load_training(self):\n",
    "        ims, labels = self.load(os.path.join(self.path, self.train_img_fname),\n",
    "                                os.path.join(self.path, self.train_lbl_fname))\n",
    "        ims = map(lambda img: img, ims)\n",
    "        self.train_images = ims\n",
    "        self.train_labels = labels\n",
    "        ims = map(lambda img: [1]+img, ims)\n",
    "        ims = np.array(ims)*1.0/255\n",
    "        mean = ims.sum(axis=1)[:,None]/785\n",
    "        ims -= mean\n",
    "        return ims, np.array(labels)\n",
    "\n",
    "    @classmethod\n",
    "    def load(cls, path_img, path_lbl):\n",
    "        with open(path_lbl, 'rb') as file:\n",
    "            magic, size = struct.unpack(\">II\", file.read(8))\n",
    "            if magic != 2049:\n",
    "                raise ValueError('Magic number mismatch, expected 2049,'\n",
    "                                 'got {}'.format(magic))\n",
    "\n",
    "            labels = array(\"B\", file.read())\n",
    "\n",
    "        with open(path_img, 'rb') as file:\n",
    "            magic, size, rows, cols = struct.unpack(\">IIII\", file.read(16))\n",
    "            if magic != 2051:\n",
    "                raise ValueError('Magic number mismatch, expected 2051,'\n",
    "                                 'got {}'.format(magic))\n",
    "\n",
    "            image_data = array(\"B\", file.read())\n",
    "\n",
    "        images = []\n",
    "        for i in range(size):\n",
    "            images.append([0] * rows * cols)\n",
    "\n",
    "        for i in range(size):\n",
    "            images[i][:] = image_data[i * rows * cols:(i + 1) * rows * cols]\n",
    "\n",
    "        return images, labels\n",
    "  \n",
    "\n",
    "    def showImage(self, imageArray, title = \"\", xlabel = \"\"):\n",
    "        imageArray = imageArray.reshape((28,28))\n",
    "        fig = plt.figure()\n",
    "        plotwindow = fig.add_subplot(111)\n",
    "        plt.xlabel(title)\n",
    "        \n",
    "        plt.imshow(imageArray, cmap='gray')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mnist = MNIST()\n",
    "trainingImgs, trainingLabels = mnist.load_training()\n",
    "testImgs, testLabels = mnist.load_testing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class MNISTClassification():\n",
    "    def __init__(self):\n",
    "        self.stepSize = 1e-3\n",
    "        self.maxIter = 1500\n",
    "        self.w_jk = None\n",
    "        self.w_ij = None\n",
    "        self.numHidden = 60\n",
    "        self.numClass = 10\n",
    "        self.batch = 1000\n",
    "        self.epsilon = 1e-2 # for check gradient\n",
    "    def fit(self, trainingImgs, trainingLabels, testImgs, testLabels, miniBatch, stepSize = None, T = 1000, checkGradient = False):\n",
    "        np.random.seed(0)\n",
    "        w_ij = np.random.normal(0, 0.1, size = (len(trainingImgs[0]), self.numHidden))\n",
    "        w_jk = np.random.normal(0, 0.1, size = (self.numHidden, self.numClass))\n",
    "        if stepSize:\n",
    "            self.stepSize = stepSize\n",
    "        \n",
    "        self.train(trainingImgs, trainingLabels, testImgs, testLabels, w_ij, w_jk, miniBatch, self.stepSize, T, checkGradient)\n",
    "        \n",
    "    def predictHidden(self, w_ij, X):\n",
    "        '''\n",
    "        X: batch * 784\n",
    "        w_ij: 784 * j\n",
    "        return: Z batch * j\n",
    "        '''\n",
    "        return 1/(1+np.exp(-np.dot(X, w_ij)))\n",
    "    \n",
    "    def predictOutput(self, w_jk, Z):\n",
    "        '''\n",
    "        Z: batch * j\n",
    "        w_jk: j * 10(= k)\n",
    "        return: prob y batch * 10(=k)\n",
    "        '''\n",
    "        expProb = np.exp(np.dot(Z, w_jk))\n",
    "        probability = expProb/expProb.sum(axis=1)[:,None] # batch * k\n",
    "        return probability\n",
    "    \n",
    "    def loss(self, X, y, w_ij, w_jk):\n",
    "        '''\n",
    "        X: batch * 784\n",
    "        y: batch\n",
    "        w_ij: 784 * j\n",
    "        w_jk: j * 10(=k)\n",
    "        '''\n",
    "        loss = 0\n",
    "        Z = self.predictHidden(w_ij, X)\n",
    "        probability = self.predictOutput(w_jk, Z)\n",
    "        t = np.zeros((len(y), self.numClass))\n",
    "        for n in range(0, len(y)):\n",
    "            t[n, y[n]] = 1\n",
    "        return -np.sum(t*np.log(probability))\n",
    "    \n",
    "    def train(self, X, y, testImgs, testLabels, w_ij, w_jk, batch, stepSize, T, checkGradient):\n",
    "        numIter = 0\n",
    "        start = 0\n",
    "        stepSize_ini = stepSize\n",
    "        while numIter < self.maxIter:\n",
    "            stepSize = stepSize_ini * 1./(1 + numIter*1./T)\n",
    "            X_batch = X[start: start + batch]\n",
    "            y_batch = y[start: start + batch]\n",
    "            \n",
    "            Z_batch = self.predictHidden(w_ij, X_batch) # batch * j\n",
    "            probability = self.predictOutput(w_jk, Z_batch) # batch * 10\n",
    "            \n",
    "            t_batch = np.zeros((len(y_batch), self.numClass)) # batch * 10\n",
    "            for n in range(0, len(y_batch)):\n",
    "                t_batch[n, y[n]] = 1\n",
    "                \n",
    "            delta_j = Z_batch*(1-Z_batch)*np.dot(t_batch - probability, w_jk.T) # batch*j\n",
    "            w_ij += stepSize / batch * np.dot(X_batch.T, delta_j)\n",
    "            w_jk += stepSize / batch * np.dot(Z_batch.T, t_batch - probability) \n",
    "            \n",
    "#             if checkGradient:\n",
    "#                 print \"Check gradient diff:\",self.checkGradient(delta_j, t_batch, X_batch, y_batch, w_ij, w_jk)\n",
    "            start += batch\n",
    "            if start == len(X):\n",
    "                start = 0\n",
    "                numIter += 1\n",
    "                if numIter % 10 == 0:\n",
    "                    print \"Number iteration:\", numIter,\", correction rate:\", self.test(testImgs, testLabels, w_ij, w_jk)\n",
    "        \n",
    "        self.w_ij = w_ij\n",
    "        self.w_jk = w_jk  \n",
    "#         return w_ij, w_jk\n",
    "\n",
    "#     def checkGradient(self, calculatedGradient, t, X, y, w_ij, w_jk):\n",
    "#         calculatedGradient = np.dot(X.T, calculatedGradient)/len(X) # i*j\n",
    "#         gradientDiff = np.zeros(calculatedGradient.shape) # i*j\n",
    "#         print calculatedGradient\n",
    "#         for i in range(0, len(w_ij)):\n",
    "#             for j in range(0, len(w_ij[0])):\n",
    "#                 w_ij[i][j] += self.epsilon\n",
    "#                 Z1= self.predictHidden(w_ij, X) # batch * j\n",
    "#                 probability1 = self.predictOutput(w_jk, Z1)\n",
    "#                 w_ij[i][j] -= self.epsilon*2\n",
    "#                 Z2= self.predictHidden(w_ij, X) # batch * j\n",
    "#                 probability2 = self.predictOutput(w_jk, Z2)\n",
    "#                 w_ij[i][j] += self.epsilon\n",
    "#                 E1 = -np.sum(t*np.log(probability1))\n",
    "#                 E2 = -np.sum(t*np.log(probability2))\n",
    "#                 gradientDiff[i][j] = abs(calculatedGradient[i][j] - (E1-E2)/2/self.epsilon)\n",
    "#         return np.max(gradientDiff)\n",
    "    \n",
    "    def test(self, X, y, w_ij, w_jk):\n",
    "        Z = self.predictHidden(w_ij, X)\n",
    "        probability = self.predictOutput(w_jk, Z)\n",
    "        predict = np.argmax(probability, axis=1) # batch\n",
    "        match = filter(lambda x: x[0] == x[1], zip(predict, y))\n",
    "        return len(match)*1.0/len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number iteration: 10 , correction rate: 0.0996\n",
      "Number iteration: 20 , correction rate: 0.1028\n",
      "Number iteration: 30 , correction rate: 0.1064\n",
      "Number iteration: 40 , correction rate: 0.1102\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-424be0035ab2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMNISTClassification\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainingImgs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m20000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainingLabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m20000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestImgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestLabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1e-3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-13-1e3ea8935b0a>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, trainingImgs, trainingLabels, testImgs, testLabels, miniBatch, stepSize, T, checkGradient)\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstepSize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstepSize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainingImgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainingLabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestImgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestLabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_ij\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_jk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminiBatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstepSize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckGradient\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredictHidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_ij\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-1e3ea8935b0a>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, X, y, testImgs, testLabels, w_ij, w_jk, batch, stepSize, T, checkGradient)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0mZ_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictHidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw_ij\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_batch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# batch * j\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0mprobability\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictOutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw_jk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mZ_batch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# batch * 10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0mt_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumClass\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# batch * 10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-1e3ea8935b0a>\u001b[0m in \u001b[0;36mpredictOutput\u001b[0;34m(self, w_jk, Z)\u001b[0m\n\u001b[1;32m     33\u001b[0m         '''\n\u001b[1;32m     34\u001b[0m         \u001b[0mexpProb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mZ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_jk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0mprobability\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexpProb\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mexpProb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# batch * k\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mprobability\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/numpy-1.10.4-py2.7-macosx-10.6-intel.egg/numpy/core/_methods.pyc\u001b[0m in \u001b[0;36m_sum\u001b[0;34m(a, axis, dtype, out, keepdims)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mumr_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_prod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "mn = MNISTClassification()\n",
    "mn.fit(trainingImgs[:20000], trainingLabels[:20000], testImgs, testLabels, 5000, 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "checkGradient = MNISTClassification()\n",
    "checkGradient.fit(trainingImgs[:10], trainingLabels[:10], testImgs, testLabels, 1, 1e-3, checkGradient = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 ..., 1 1 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.1135, array([[ 0.05100418,  0.19265873,  0.0998006 , ...,  0.05086599,\n",
       "          0.0503934 ,  0.10267014],\n",
       "        [ 0.05100534,  0.19265545,  0.09980087, ...,  0.05086715,\n",
       "          0.05039457,  0.10267032],\n",
       "        [ 0.02360222,  0.30463916,  0.08590524, ...,  0.0234793 ,\n",
       "          0.02306127,  0.09072211],\n",
       "        ..., \n",
       "        [ 0.0510143 ,  0.19263018,  0.09980293, ...,  0.05087612,\n",
       "          0.05040357,  0.10267178],\n",
       "        [ 0.05090476,  0.19293944,  0.09977762, ...,  0.05076648,\n",
       "          0.05029362,  0.10265396],\n",
       "        [ 0.05101437,  0.19262997,  0.09980295, ...,  0.05087619,\n",
       "          0.05040364,  0.10267179]]), array([1, 1, 1, ..., 1, 1, 1]))"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(testImgs, testLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def test(X, y):\n",
    "    Z = mn.predictHidden(mn.w_ij, X)\n",
    "    probability = mn.predictOutput(mn.w_jk, Z)\n",
    "    predict = np.argmax(probability, axis=1) # batch\n",
    "    match = sum([x[0] == x[1] for x in zip(predict, y)])\n",
    "    return match*1.0/len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.2,  0.4,  0.2,  0.2],\n",
       "       [ 0.2,  0.4,  0.2,  0.2],\n",
       "       [ 0.2,  0.4,  0.2,  0.2],\n",
       "       [ 0.2,  0.4,  0.2,  0.2],\n",
       "       [ 0.2,  0.4,  0.2,  0.2]])"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a/a.sum(axis=1)[:,None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.71838414,  0.94008238],\n",
       "       [ 0.88048577,  0.59965128]])"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.random((2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2],\n",
       "       [1, 2]])"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.abs(np.array([[1,2],[1,-2]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
