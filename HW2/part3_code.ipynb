{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plotUpdate(first, second, third, title, firstLabel, secondLabel, thirdLabel, ylabel, ylim, loc = False):\n",
    "    firstLine, = plt.plot([i for i in range(0,len(first))], first)\n",
    "    secontLine, = plt.plot([i for i in range(0,len(second))], second)\n",
    "    thirdLine, = plt.plot([i for i in range(0,len(third))], third)\n",
    "    plt.xlabel('t')\n",
    "    plt.ylim(ylim)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.title(title)\n",
    "    if loc:\n",
    "        plt.legend([firstLine, secontLine, thirdLine], [firstLabel, secondLabel, thirdLabel], loc = (0.624,0))\n",
    "    else:\n",
    "        plt.legend([firstLine, secontLine, thirdLine], [firstLabel, secondLabel, thirdLabel])\n",
    "    plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import struct\n",
    "from array import array\n",
    "\n",
    "\n",
    "class MNIST(object):\n",
    "    def __init__(self, path='../HW1/dataset'):\n",
    "        self.path = path\n",
    "\n",
    "        self.test_img_fname = 't10k-images-idx3-ubyte'\n",
    "        self.test_lbl_fname = 't10k-labels-idx1-ubyte'\n",
    "\n",
    "        self.train_img_fname = 'train-images-idx3-ubyte'\n",
    "        self.train_lbl_fname = 'train-labels-idx1-ubyte'\n",
    "\n",
    "        self.test_images = []\n",
    "        self.test_labels = []\n",
    "\n",
    "        self.train_images = []\n",
    "        self.train_labels = []\n",
    "\n",
    "    def load_testing(self):\n",
    "        ims, labels = self.load(os.path.join(self.path, self.test_img_fname),\n",
    "                                os.path.join(self.path, self.test_lbl_fname))\n",
    "        ims = map(lambda img: img, ims)\n",
    "        self.test_images = ims\n",
    "        self.test_labels = labels\n",
    "        ims = map(lambda img: [255]+img, ims)\n",
    "        ims = np.array(ims)*1.0/255\n",
    "        mean = ims.sum(axis=1)[:,None]/785\n",
    "        ims -= mean\n",
    "        return ims, np.array(labels)\n",
    "\n",
    "    def load_training(self):\n",
    "        ims, labels = self.load(os.path.join(self.path, self.train_img_fname),\n",
    "                                os.path.join(self.path, self.train_lbl_fname))\n",
    "        ims = map(lambda img: img, ims)\n",
    "        self.train_images = ims\n",
    "        self.train_labels = labels\n",
    "        ims = map(lambda img: [255]+img, ims)\n",
    "        ims = np.array(ims)*1.0/255\n",
    "        mean = ims.sum(axis=1)[:,None]/785\n",
    "        ims -= mean\n",
    "        return ims, np.array(labels)\n",
    "\n",
    "    @classmethod\n",
    "    def load(cls, path_img, path_lbl):\n",
    "        with open(path_lbl, 'rb') as file:\n",
    "            magic, size = struct.unpack(\">II\", file.read(8))\n",
    "            if magic != 2049:\n",
    "                raise ValueError('Magic number mismatch, expected 2049,'\n",
    "                                 'got {}'.format(magic))\n",
    "\n",
    "            labels = array(\"B\", file.read())\n",
    "\n",
    "        with open(path_img, 'rb') as file:\n",
    "            magic, size, rows, cols = struct.unpack(\">IIII\", file.read(16))\n",
    "            if magic != 2051:\n",
    "                raise ValueError('Magic number mismatch, expected 2051,'\n",
    "                                 'got {}'.format(magic))\n",
    "\n",
    "            image_data = array(\"B\", file.read())\n",
    "\n",
    "        images = []\n",
    "        for i in range(size):\n",
    "            images.append([0] * rows * cols)\n",
    "\n",
    "        for i in range(size):\n",
    "            images[i][:] = image_data[i * rows * cols:(i + 1) * rows * cols]\n",
    "\n",
    "        return images, labels\n",
    "  \n",
    "\n",
    "    def showImage(self, imageArray, title = \"\", xlabel = \"\"):\n",
    "        imageArray = imageArray.reshape((28,28))\n",
    "        fig = plt.figure()\n",
    "        plotwindow = fig.add_subplot(111)\n",
    "        plt.xlabel(title)\n",
    "        \n",
    "        plt.imshow(imageArray, cmap='gray')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mnist = MNIST()\n",
    "trainingImgs, trainingLabels = mnist.load_training()\n",
    "testImgs, testLabels = mnist.load_testing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class MNISTClassification():\n",
    "    def __init__(self):\n",
    "        self.stepSize = 1e-3\n",
    "        self.maxIter = 0\n",
    "        self.w_jk = None\n",
    "        self.w_ij = None\n",
    "        self.numHidden = 60\n",
    "        self.numClass = 10\n",
    "        self.epsilon = 1e-2 # for check gradient\n",
    "        \n",
    "        self.trainAccuracyPath = []\n",
    "        self.validationAccuracyPath = []\n",
    "        self.testAccuracyPath = []\n",
    "        self.maxValidationAccuracy = -1\n",
    "        self.w_ijPath = []\n",
    "        self.w_jkPath = []\n",
    "        self.preHiddenGradient = 0\n",
    "        self.preOutputGradient = 0\n",
    "        self.optimize = False\n",
    "        \n",
    "    def fit(self, trainingImgs, trainingLabels, testImgs, testLabels, miniBatch,\\\n",
    "            stepSize = None, T = 1000, checkGradient = False, numHidden = 60, maxIter = 1000, optimize = False):\n",
    "        self.numHidden = numHidden\n",
    "        np.random.seed(0)\n",
    "        w_ij = np.random.normal(0, 0.1, size = (len(trainingImgs[0]), self.numHidden))\n",
    "        w_jk = np.random.normal(0, 0.1, size = (self.numHidden + 1, self.numClass))\n",
    "        if optimize:\n",
    "            w_ij = np.random.normal(0, 1/math.sqrt(len(trainingImgs[0])), size = (len(trainingImgs[0]), self.numHidden))\n",
    "            w_jk = np.random.normal(0, 1/math.sqrt(self.numHidden), size = (self.numHidden + 1, self.numClass))\n",
    "        if stepSize:\n",
    "            self.stepSize = stepSize\n",
    "        self.optimize = optimize\n",
    "        \n",
    "        self.maxIter = maxIter\n",
    "        \n",
    "        self.train(trainingImgs, trainingLabels, testImgs, testLabels, w_ij, w_jk, miniBatch,\\\n",
    "                   self.stepSize, T, checkGradient, numHidden)\n",
    "        \n",
    "    def predictHidden(self, w_ij, X):\n",
    "        '''\n",
    "        X: batch * 784\n",
    "        w_ij: 784 * j\n",
    "        return: Z batch * j\n",
    "        '''\n",
    "        if self.optimize:\n",
    "            return 1.7159*np.tanh(2./3.*np.dot(X, w_ij)) # part4\n",
    "        return 1/(1+np.exp(-np.dot(X, w_ij))) #part3\n",
    "    \n",
    "    def predictOutput(self, w_jk, Z):\n",
    "        '''\n",
    "        Z: batch * j\n",
    "        w_jk: j * 10(= k)\n",
    "        return: prob y batch * 10(=k)\n",
    "        '''\n",
    "        expProb = np.exp(np.dot(Z, w_jk))\n",
    "        probability = expProb/expProb.sum(axis=1)[:,None] # batch * k\n",
    "        return probability\n",
    "    \n",
    "    def loss(self, X, y, t, w_ij, w_jk):\n",
    "        '''\n",
    "        X: batch * 784\n",
    "        y: batch\n",
    "        w_ij: 784 * j\n",
    "        w_jk: j * 10(=k)\n",
    "        '''\n",
    "        loss = 0\n",
    "        Z = self.predictHidden(w_ij, X)\n",
    "        probability = self.predictOutput(w_jk, Z)\n",
    "        return -np.sum(t*np.log(probability))\n",
    "    \n",
    "    def train(self, X, y, testImgs, testLabels, w_ij, w_jk, batch, stepSize, T, checkGradient, numHidden):\n",
    "        numIter = 0\n",
    "        start = 0\n",
    "        stepSize_ini = stepSize\n",
    "        eta = 0.9 #1/(1+ np.exp(-numIter/250)) # momentum parameter\n",
    "        # Split validation and training\n",
    "        partial = int(math.ceil(len(X)/6.*5.))\n",
    "        validationImgs = X[partial:]\n",
    "        validationLabels = y[partial:]\n",
    "        X = X[:partial]\n",
    "        y = y[:partial]\n",
    "        \n",
    "        while numIter < self.maxIter:\n",
    "            stepSize = stepSize_ini * 1./(1 + numIter*1./T) # learning rate\n",
    "            end = min(start + batch, len(X))\n",
    "                \n",
    "            X_batch = X[start: end]\n",
    "            y_batch = y[start: end]\n",
    "            \n",
    "            Z_batch = self.predictHidden(w_ij, X_batch) # batch * j\n",
    "            Z_batch = np.hstack([np.ones((len(Z_batch),1)), Z_batch]) #  batch * (j+1)(add bias to Z)\n",
    "            probability = self.predictOutput(w_jk, Z_batch) # batch * 10  \n",
    "            \n",
    "            t_batch = np.zeros((len(y_batch), self.numClass)) # batch * 10\n",
    "            for n in range(0, len(y_batch)):\n",
    "                t_batch[n, y[n]] = 1\n",
    "            \n",
    "            delta_k = t_batch - probability\n",
    "            \n",
    "            if self.optimize: # tanh softmax for hiddenlayer\n",
    "                delta_j = (2./3*(1.7159 - (Z_batch**2)/1.7159)* np.dot(delta_k, w_jk.T))[:,1:]# batch*j #part4\n",
    "            else:\n",
    "                delta_j = (Z_batch*(1-Z_batch)*np.dot(delta_k, w_jk.T))[:, 1:] # batch * j #part3 delete\n",
    "            \n",
    "            if checkGradient:\n",
    "                print \"Check gradient diff:\", self.checkGradient(-delta_j, -delta_k, t_batch, X_batch, y_batch, Z_batch, w_ij, w_jk)\n",
    "                break\n",
    "                \n",
    "            w_ij_update = stepSize / len(X_batch) * np.dot(X_batch.T, delta_j)\n",
    "            w_jk_update = stepSize / len(X_batch) * np.dot(Z_batch.T, delta_k) \n",
    "            \n",
    "            if self.optimize: # momentum\n",
    "                w_ij_update += eta*self.preHiddenGradient\n",
    "                w_jk_update += eta*self.preOutputGradient\n",
    "                self.preHiddenGradient = w_ij_update\n",
    "                self.preOutputGradient = w_jk_update\n",
    "               \n",
    "            w_ij += w_ij_update\n",
    "            w_jk += w_jk_update\n",
    "            start = end\n",
    "            \n",
    "            if start >= len(X):\n",
    "                start = 0\n",
    "                numIter += 1\n",
    "                stepSize = stepSize_ini * 1./(1 + numIter*1./T)\n",
    "                self.trainAccuracyPath.append(self.test(X, y, w_ij, w_jk))\n",
    "                validationAccuracy = self.test(validationImgs, validationLabels, w_ij, w_jk)\n",
    "                self.validationAccuracyPath.append(validationAccuracy)\n",
    "                \n",
    "                # record the weights where the validation accuracy is maximum\n",
    "                if validationAccuracy > self.maxValidationAccuracy:\n",
    "                    self.w_ij = w_ij\n",
    "                    self.w_jk = w_jk\n",
    "                    self.maxValidationAccuracy = validationAccuracy\n",
    "                self.testAccuracyPath.append(self.test(trainingImgs, trainingLabels, w_ij, w_jk))\n",
    "                \n",
    "                # early stopping\n",
    "                if len(self.validationAccuracyPath) > 100 and \\\n",
    "                self.validationAccuracyPath[-4] > self.validationAccuracyPath[-3] > \\\n",
    "                self.validationAccuracyPath[-2] > self.validationAccuracyPath[-1]:\n",
    "                    print \"Converge at \", numIter, \"final correction rate is\", self.testAccuracyPath[-3]\n",
    "#                     break\n",
    "                    \n",
    "                if numIter % 10 == 0:\n",
    "                    print \"Number iteration:\", numIter,\", correction rate:\", self.testAccuracyPath[-1]\n",
    "\n",
    "    def checkGradient(self, hiddenLayerGradient, OutputLayerGradient, t, X, y, Z, w_ij, w_jk):\n",
    "        # Check w_ij gradient\n",
    "        hiddenLayerGradient = np.dot(X.T, hiddenLayerGradient)/len(X) # i*j\n",
    "        gradientDiffWij = np.zeros(hiddenLayerGradient.shape) # i*j\n",
    "        epsilonMatrix = np.zeros(w_ij.shape)\n",
    "        for i in range(0, len(w_ij)):\n",
    "            for j in range(0, len(w_ij[0])):\n",
    "                epsilonMatrix[i][j] += self.epsilon\n",
    "                Z1 = self.predictHidden(w_ij + epsilonMatrix, X)\n",
    "                probability1 = self.predictOutput(w_jk, np.hstack([np.ones((len(Z1),1)), Z1]))\n",
    "                Z2 = self.predictHidden(w_ij - epsilonMatrix, X)\n",
    "                probability2 = self.predictOutput(w_jk, np.hstack([np.ones((len(Z2),1)), Z2]))\n",
    "                E1 = -np.sum(t*np.log(probability1))\n",
    "                E2 = -np.sum(t*np.log(probability2))\n",
    "                gradientDiffWij[i][j] = abs(hiddenLayerGradient[i][j] - (E1-E2)/2/self.epsilon)\n",
    "                epsilonMatrix[i][j] -= self.epsilon\n",
    "        # check w_jk gradient\n",
    "        epsilonMatrix = np.zeros(w_jk.shape)\n",
    "        OutputLayerGradient = np.dot(Z.T, OutputLayerGradient)/len(Z) # j*k\n",
    "        gradientDiffWjk = np.zeros(OutputLayerGradient.shape) # j*k\n",
    "        for j in range(0, len(w_jk)):\n",
    "            for k in range(0, len(w_jk[0])):\n",
    "                epsilonMatrix[j][k] += self.epsilon\n",
    "                probability1 = self.predictOutput(w_jk + epsilonMatrix, Z)\n",
    "                probability2 = self.predictOutput(w_jk - epsilonMatrix, Z)\n",
    "                E1 = -np.sum(t*np.log(probability1))\n",
    "                E2 = -np.sum(t*np.log(probability2))\n",
    "                gradientDiffWjk[j][k] = abs(OutputLayerGradient[j][k] - (E1-E2)/2/self.epsilon)\n",
    "                epsilonMatrix[j][k] -= self.epsilon\n",
    "\n",
    "        return np.mean(gradientDiffWij), np.mean(gradientDiffWjk), np.max(gradientDiffWij), np.max(gradientDiffWjk)\n",
    "    \n",
    "    def test(self, X, y, w_ij, w_jk):\n",
    "        Z = self.predictHidden(w_ij, X)\n",
    "        probability = self.predictOutput(w_jk, np.hstack([np.ones((len(Z),1)), Z]))\n",
    "        predict = np.argmax(probability, axis=1) # batch\n",
    "        match = filter(lambda x: x[0] == x[1], zip(predict, y))\n",
    "        return len(match)*1.0/len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number iteration: 10 , correction rate: 0.633933333333\n",
      "Number iteration: 20 , correction rate: 0.862633333333\n",
      "Number iteration: 30 , correction rate: 0.9024\n",
      "Number iteration: 40 , correction rate: 0.936616666667\n",
      "Number iteration: 50 , correction rate: 0.951666666667\n",
      "Number iteration: 60 , correction rate: 0.959616666667\n",
      "Number iteration: 70 , correction rate: 0.965383333333\n",
      "Number iteration: 80 , correction rate: 0.969933333333\n",
      "Number iteration: 90 , correction rate: 0.973116666667\n",
      "Number iteration: 100 , correction rate: 0.97515\n",
      "Number iteration: 110 , correction rate: 0.976966666667\n",
      "Number iteration: 120 , correction rate: 0.978983333333\n",
      "Number iteration: 130 , correction rate: 0.980466666667\n",
      "Number iteration: 140 , correction rate: 0.98175\n",
      "Number iteration: 150 , correction rate: 0.982983333333\n",
      "Number iteration: 160 , correction rate: 0.984183333333\n",
      "Number iteration: 170 , correction rate: 0.985366666667\n",
      "Number iteration: 180 , correction rate: 0.98635\n",
      "Number iteration: 190 , correction rate: 0.987083333333\n",
      "Number iteration: 200 , correction rate: 0.987916666667\n",
      "Number iteration: 210 , correction rate: 0.9885\n",
      "Number iteration: 220 , correction rate: 0.98905\n",
      "Number iteration: 230 , correction rate: 0.989533333333\n",
      "Number iteration: 240 , correction rate: 0.990116666667\n",
      "Number iteration: 250 , correction rate: 0.990466666667\n",
      "Number iteration: 260 , correction rate: 0.9907\n",
      "Number iteration: 270 , correction rate: 0.991116666667\n",
      "Number iteration: 280 , correction rate: 0.991433333333\n",
      "Number iteration: 290 , correction rate: 0.991716666667\n",
      "Number iteration: 300 , correction rate: 0.992083333333\n",
      "Number iteration: 310 , correction rate: 0.992383333333\n",
      "Number iteration: 320 , correction rate: 0.992533333333\n",
      "Number iteration: 330 , correction rate: 0.992683333333\n",
      "Number iteration: 340 , correction rate: 0.99285\n",
      "Number iteration: 350 , correction rate: 0.99305\n",
      "Number iteration: 360 , correction rate: 0.9932\n",
      "Number iteration: 370 , correction rate: 0.993333333333\n",
      "Number iteration: 380 , correction rate: 0.9935\n",
      "Number iteration: 390 , correction rate: 0.993583333333\n",
      "Number iteration: 400 , correction rate: 0.993683333333\n",
      "Number iteration: 410 , correction rate: 0.9938\n",
      "Number iteration: 420 , correction rate: 0.9939\n",
      "Number iteration: 430 , correction rate: 0.994066666667\n",
      "Number iteration: 440 , correction rate: 0.9942\n",
      "Number iteration: 450 , correction rate: 0.994283333333\n",
      "Number iteration: 460 , correction rate: 0.994366666667\n",
      "Number iteration: 470 , correction rate: 0.9944\n",
      "Number iteration: 480 , correction rate: 0.994433333333\n",
      "Number iteration: 490 , correction rate: 0.994433333333\n",
      "Number iteration: 500 , correction rate: 0.994433333333\n",
      "Number iteration: 510 , correction rate: 0.99445\n",
      "Number iteration: 520 , correction rate: 0.994466666667\n",
      "Number iteration: 530 , correction rate: 0.994533333333\n",
      "Number iteration: 540 , correction rate: 0.994533333333\n",
      "Number iteration: 550 , correction rate: 0.994566666667\n",
      "Number iteration: 560 , correction rate: 0.994616666667\n",
      "Number iteration: 570 , correction rate: 0.994633333333\n",
      "Number iteration: 580 , correction rate: 0.994666666667\n",
      "Number iteration: 590 , correction rate: 0.994683333333\n",
      "Number iteration: 600 , correction rate: 0.9947\n",
      "Number iteration: 610 , correction rate: 0.99475\n",
      "Number iteration: 620 , correction rate: 0.994766666667\n",
      "Number iteration: 630 , correction rate: 0.994766666667\n",
      "Number iteration: 640 , correction rate: 0.9948\n",
      "Number iteration: 650 , correction rate: 0.994833333333\n",
      "Number iteration: 660 , correction rate: 0.994883333333\n",
      "Number iteration: 670 , correction rate: 0.994933333333\n",
      "Number iteration: 680 , correction rate: 0.99495\n",
      "Number iteration: 690 , correction rate: 0.994983333333\n",
      "Number iteration: 700 , correction rate: 0.995016666667\n",
      "Number iteration: 710 , correction rate: 0.99505\n",
      "Number iteration: 720 , correction rate: 0.995016666667\n",
      "Number iteration: 730 , correction rate: 0.995033333333\n",
      "Number iteration: 740 , correction rate: 0.99505\n",
      "Number iteration: 750 , correction rate: 0.995083333333\n",
      "Number iteration: 760 , correction rate: 0.995116666667\n",
      "Number iteration: 770 , correction rate: 0.995133333333\n",
      "Number iteration: 780 , correction rate: 0.995133333333\n",
      "Number iteration: 790 , correction rate: 0.995116666667\n",
      "Number iteration: 800 , correction rate: 0.995116666667\n",
      "Number iteration: 810 , correction rate: 0.995116666667\n",
      "Number iteration: 820 , correction rate: 0.995133333333\n",
      "Number iteration: 830 , correction rate: 0.995166666667\n",
      "Number iteration: 840 , correction rate: 0.99515\n",
      "Number iteration: 850 , correction rate: 0.99515\n",
      "Number iteration: 860 , correction rate: 0.99515\n",
      "Number iteration: 870 , correction rate: 0.995133333333\n",
      "Number iteration: 880 , correction rate: 0.995116666667\n",
      "Number iteration: 890 , correction rate: 0.99515\n",
      "Number iteration: 900 , correction rate: 0.99515\n",
      "Number iteration: 910 , correction rate: 0.99515\n",
      "Number iteration: 920 , correction rate: 0.995166666667\n",
      "Number iteration: 930 , correction rate: 0.995183333333\n",
      "Number iteration: 940 , correction rate: 0.995183333333\n",
      "Number iteration: 950 , correction rate: 0.9952\n",
      "Number iteration: 960 , correction rate: 0.9952\n",
      "Number iteration: 970 , correction rate: 0.9952\n",
      "Number iteration: 980 , correction rate: 0.995216666667\n",
      "Number iteration: 990 , correction rate: 0.995216666667\n",
      "Number iteration: 1000 , correction rate: 0.995216666667\n"
     ]
    }
   ],
   "source": [
    "mn = MNISTClassification()\n",
    "mn.fit(trainingImgs, trainingLabels, testImgs, testLabels, 60000, 1, T = 700, numHidden = 120, maxIter = 1000, optimize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZEAAAEZCAYAAABWwhjiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x106eb0b10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plotUpdate(mn.trainAccuracyPath, mn.validationAccuracyPath, mn.testAccuracyPath, 'Correction rate over training',\n",
    "           'training set', 'validation set','test set', \"percent correct classification\",[0.7,1.01], True)\n",
    "plt.savefig('part5_whole_120unit_1_700.png', bbox_inches='tight') #Number iteration: 1000 , correction rate: 0.928116666667"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 & 0.97782 & 0.9618 & 0.97515\n",
      "200 & 0.99186 & 0.9682 & 0.987916666667\n",
      "300 & 0.99654 & 0.9698 & 0.992083333333\n",
      "400 & 0.99836 & 0.9703 & 0.993683333333\n",
      "500 & 0.99924 & 0.9704 & 0.994433333333\n",
      "600 & 0.99958 & 0.9703 & 0.9947\n",
      "700 & 0.99982 & 0.971 & 0.995016666667\n",
      "800 & 0.99992 & 0.9711 & 0.995116666667\n",
      "900 & 0.99996 & 0.9711 & 0.99515\n",
      "1000 & 0.99998 & 0.9714 & 0.995216666667\n"
     ]
    }
   ],
   "source": [
    "for i in [100,200,300,400,500,600,700,800,900,1000]:\n",
    "    print i,\"&\",mn.trainAccuracyPath[i-1],\"&\", mn.validationAccuracyPath[i-1],\"&\", mn.testAccuracyPath[i-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check gradient diff: (1.1916369640615067e-08, 1.5967735680372368e-07, 3.3150166168366413e-07, 1.6028107083787546e-06)\n"
     ]
    }
   ],
   "source": [
    "checkGradient = MNISTClassification()\n",
    "checkGradient.fit(trainingImgs[:1], trainingLabels[:1], testImgs, testLabels, 1, 1, checkGradient = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "randomData = zip(trainingImgs, trainingLabels)\n",
    "random.seed(2)\n",
    "random.shuffle(randomData)\n",
    "randomTrainImgs, randomTrainLabels = np.array(map(lambda x:x[0], randomData)), np.array(map(lambda x:x[1], randomData))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "optimalMN = MNISTClassification()\n",
    "optimalMN.fit(randomTrainImgs, randomTrainLabels, testImgs, testLabels, 1000, 0.005, T = 20, numHidden = 60, optimize = True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plotUpdate(optimalMN.trainAccuracyPath, optimalMN.validationAccuracyPath, optimalMN.testAccuracyPath, 'Correction rate over training',\n",
    "           'training set', 'validation set','test set', \"percent correct classification\",[0,0.9], True)\n",
    "# plt.savefig('part4_10000_02_50.png', bbox_inches='tight') #Number iteration: 1000 , correction rate: 0.928116666667"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
