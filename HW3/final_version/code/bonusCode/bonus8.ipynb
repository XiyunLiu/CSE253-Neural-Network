{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using gpu device 0: GeForce GTX 1080 (CNMeM is disabled, cuDNN not available)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "from scipy import ndimage\n",
    "from skimage import transform\n",
    "import keras\n",
    "from keras.layers import Dense, Lambda\n",
    "from keras.applications import VGG16\n",
    "from keras.models import Model\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import Callback, ModelCheckpoint, EarlyStopping\n",
    "import skimage.io as io\n",
    "\n",
    "# MEAN = np.array([123.0, 117.0, 104.0])\n",
    "MEAN = np.array([0, 0, 0])\n",
    "def getModel( output_dim ):\n",
    "    ''' \n",
    "        * output_dim: the number of classes (int)\n",
    "        \n",
    "        * return: compiled model (keras.engine.training.Model)\n",
    "    '''\n",
    "    vgg_model = VGG16( weights='imagenet', include_top=True )\n",
    "#     vgg_out = vgg_model.layers[-2].output #Last FC layer's output \n",
    "    layer_name = 'fc2'\n",
    "    x = vgg_model.get_layer(layer_name).output\n",
    "    temper = 8.0;\n",
    "    x = Lambda(lambda x: x/temper)(x)\n",
    "    \n",
    "    layer_name = 'predictions'\n",
    "    pred_layer = vgg_model.get_layer(layer_name) \n",
    "    weight = pred_layer.get_weights()\n",
    "    x = Dense(1000, activation='softmax', name='softmax1', weights=weight)(x) \n",
    "    \n",
    "    softmax_layer = Dense(256, activation='softmax')(x) #Create softmax layer taking input as vgg_ou\n",
    "    #Create new transfer learning model\n",
    "    tl_model = Model( input=vgg_model.input, output=softmax_layer )\n",
    "\n",
    "    #Freeze all layers of VGG16 and Compile the model\n",
    "    #Confirm the model is appropriate\n",
    "    for l in vgg_model.layers:\n",
    "        l.trainable = False\n",
    "        \n",
    "    layer_name = 'softmax1'\n",
    "    tl_model.get_layer(layer_name).trainable = False\n",
    "#     tl_model.get_layer(layer_name).set_weights(weights)\n",
    "    \n",
    "    tl_model.summary()\n",
    "\n",
    "    return tl_model\n",
    "def convert_image(collect):\n",
    "#     sz = np.shape(collect)[0]\n",
    "    sz = len(collect)\n",
    "    images = np.zeros((sz, 224, 224, 3))\n",
    "    for i in range(sz):\n",
    "        img = collect[i]\n",
    "        img = transform.resize(img, (224, 224))*255\n",
    "        if (len(img.shape) != 3):\n",
    "           img = img[:,:,np.newaxis]\n",
    "        images[i] = img\n",
    "    return images\n",
    "\n",
    "sizeOfEachClass = 16\n",
    "sizeOfTestEachClass = 16\n",
    "path='/home/yiluo/Homework/253/3/256_ObjectCategories/'\n",
    "files = os.listdir(path)\n",
    "X_train, X_val, X_test = [], [], []\n",
    "Y_train, Y_val, Y_test = [], [], []\n",
    "label = 0\n",
    "for category in files:\n",
    "    sub_path = path + category\n",
    "    sub_files = os.listdir(sub_path)\n",
    "    cnt = np.shape(sub_files)[0]\n",
    "    num = 1\n",
    "    for img_nm in sub_files:\n",
    "        if img_nm[-4:] == '.jpg':\n",
    "            img_path = sub_path + '/' + img_nm\n",
    "            #img = ndimage.imread(sub_path + '/' + img_nm)\n",
    "            #img = transform.resize(img, (224, 224))*255\n",
    "            if num <= np.floor(0.8*cnt):\n",
    "                if num <= sizeOfEachClass:\n",
    "                    X_train.append(img_path)\n",
    "                    Y_train.append(label)\n",
    "            elif num <= np.floor(0.9*cnt):\n",
    "                if num <= np.floor(0.8*cnt) + sizeOfTestEachClass:\n",
    "                    X_val.append(img_path)\n",
    "                    Y_val.append(label)\n",
    "            else:\n",
    "                X_test.append(img_path)\n",
    "                Y_test.append(label)\n",
    "            num += 1\n",
    "    label += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#shuffle\n",
    "ind=range(int(len(X_train)))\n",
    "random.shuffle(ind)\n",
    "X_train = [X_train[i] for i in ind]\n",
    "Y_train = [Y_train[i] for i in ind]\n",
    "Y_train_label = np.zeros((len(Y_train), 256))\n",
    "for i in range(len(Y_train)):\n",
    "    Y_train_label[i, Y_train[i]] = 1\n",
    "    \n",
    "#validation  \n",
    "Y_val_label = np.zeros((len(Y_val), 256))\n",
    "for i in range(len(Y_val)):\n",
    "    Y_val_label[i, Y_val[i]] = 1\n",
    "    \n",
    "#test\n",
    "Y_test_label = np.zeros((len(Y_test), 256))\n",
    "for i in range(len(Y_test)):\n",
    "    Y_test_label[i, Y_test[i]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Output dim for your dataset\n",
    "output_dim = 256 #For Caltech256\n",
    "\n",
    "#Data\n",
    "coll = io.ImageCollection(X_train)\n",
    "X_train_data = convert_image(coll)\n",
    "# coll_val = io.ImageCollection(X_val)\n",
    "# X_val_data = convert_image(coll_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/Keras-1.2.2-py2.7.egg/keras/layers/core.py:622: UserWarning: `output_shape` argument not specified for layer lambda_3 and cannot be automatically inferred with the Theano backend. Defaulting to output shape `(None, 4096)` (same as input shape). If the expected output shape is different, specify it via the `output_shape` argument.\n",
      "  .format(self.name, input_shape))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_3 (InputLayer)             (None, 224, 224, 3)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "block1_conv1 (Convolution2D)     (None, 224, 224, 64)  1792        input_3[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "block1_conv2 (Convolution2D)     (None, 224, 224, 64)  36928       block1_conv1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block1_pool (MaxPooling2D)       (None, 112, 112, 64)  0           block1_conv2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block2_conv1 (Convolution2D)     (None, 112, 112, 128) 73856       block1_pool[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "block2_conv2 (Convolution2D)     (None, 112, 112, 128) 147584      block2_conv1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)       (None, 56, 56, 128)   0           block2_conv2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block3_conv1 (Convolution2D)     (None, 56, 56, 256)   295168      block2_pool[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "block3_conv2 (Convolution2D)     (None, 56, 56, 256)   590080      block3_conv1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block3_conv3 (Convolution2D)     (None, 56, 56, 256)   590080      block3_conv2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)       (None, 28, 28, 256)   0           block3_conv3[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block4_conv1 (Convolution2D)     (None, 28, 28, 512)   1180160     block3_pool[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "block4_conv2 (Convolution2D)     (None, 28, 28, 512)   2359808     block4_conv1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block4_conv3 (Convolution2D)     (None, 28, 28, 512)   2359808     block4_conv2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)       (None, 14, 14, 512)   0           block4_conv3[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block5_conv1 (Convolution2D)     (None, 14, 14, 512)   2359808     block4_pool[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "block5_conv2 (Convolution2D)     (None, 14, 14, 512)   2359808     block5_conv1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block5_conv3 (Convolution2D)     (None, 14, 14, 512)   2359808     block5_conv2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block5_pool (MaxPooling2D)       (None, 7, 7, 512)     0           block5_conv3[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "flatten (Flatten)                (None, 25088)         0           block5_pool[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "fc1 (Dense)                      (None, 4096)          102764544   flatten[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "fc2 (Dense)                      (None, 4096)          16781312    fc1[0][0]                        \n",
      "____________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)                (None, 4096)          0           fc2[0][0]                        \n",
      "____________________________________________________________________________________________________\n",
      "softmax1 (Dense)                 (None, 1000)          4097000     lambda_3[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                  (None, 256)           256256      softmax1[0][0]                   \n",
      "====================================================================================================\n",
      "Total params: 138,613,800\n",
      "Trainable params: 256,256\n",
      "Non-trainable params: 138,357,544\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Model\n",
    "tl_model = getModel( output_dim )\n",
    "# rmsprop = keras.optimizers.RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0) # error\n",
    "\n",
    "# tl_model.compile(loss='categorical_crossentropy', optimizer='adadelta', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sgd = keras.optimizers.SGD(lr=2, momentum=0.9, decay=0.0, nesterov=True)\n",
    "# tl_model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "\n",
    "adam = keras.optimizers.Adam(lr=1, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "tl_model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "\n",
    "# adagrad = keras.optimizers.Adagrad(lr=2, epsilon=1e-08, decay=0.0)\n",
    "# tl_model.compile(loss='categorical_crossentropy', optimizer=adagrad, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    samplewise_center=True)\n",
    "\n",
    "# compute quantities required for featurewise normalization\n",
    "# (std, mean, and principal components if ZCA whitening is applied)\n",
    "datagen.fit(X_train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2048 samples, validate on 2048 samples\n",
      "Epoch 1/20\n",
      "2048/2048 [==============================] - 84s - loss: 7.3957 - acc: 0.0107 - val_loss: 6.7090 - val_acc: 0.0283\n",
      "Epoch 2/20\n",
      "2048/2048 [==============================] - 84s - loss: 5.8029 - acc: 0.0522 - val_loss: 5.7863 - val_acc: 0.0693\n",
      "Epoch 3/20\n",
      "2048/2048 [==============================] - 83s - loss: 5.0716 - acc: 0.1221 - val_loss: 5.4842 - val_acc: 0.1011\n",
      "Epoch 4/20\n",
      "2048/2048 [==============================] - 83s - loss: 4.4759 - acc: 0.1914 - val_loss: 5.1035 - val_acc: 0.1372\n",
      "Epoch 5/20\n",
      "2048/2048 [==============================] - 48s - loss: 4.0288 - acc: 0.2495 - val_loss: 4.8052 - val_acc: 0.1602\n",
      "Epoch 6/20\n",
      "2048/2048 [==============================] - 45s - loss: 3.6549 - acc: 0.2949 - val_loss: 4.5914 - val_acc: 0.1660\n",
      "Epoch 7/20\n",
      "2048/2048 [==============================] - 56s - loss: 3.3784 - acc: 0.3369 - val_loss: 4.4083 - val_acc: 0.2051\n",
      "Epoch 8/20\n",
      "2048/2048 [==============================] - 82s - loss: 3.1084 - acc: 0.3789 - val_loss: 4.2603 - val_acc: 0.2188\n",
      "Epoch 9/20\n",
      "2048/2048 [==============================] - 84s - loss: 2.8757 - acc: 0.4165 - val_loss: 4.1359 - val_acc: 0.2217\n",
      "Epoch 10/20\n",
      "2048/2048 [==============================] - 85s - loss: 2.6810 - acc: 0.4536 - val_loss: 4.0099 - val_acc: 0.2505\n",
      "Epoch 11/20\n",
      "2048/2048 [==============================] - 85s - loss: 2.5095 - acc: 0.4810 - val_loss: 3.9340 - val_acc: 0.2642\n",
      "Epoch 12/20\n",
      "2048/2048 [==============================] - 85s - loss: 2.3504 - acc: 0.5088 - val_loss: 3.8486 - val_acc: 0.2729\n",
      "Epoch 13/20\n",
      "2048/2048 [==============================] - 84s - loss: 2.2194 - acc: 0.5312 - val_loss: 3.7714 - val_acc: 0.2822\n",
      "Epoch 14/20\n",
      "2048/2048 [==============================] - 82s - loss: 2.0847 - acc: 0.5630 - val_loss: 3.7238 - val_acc: 0.2881\n",
      "Epoch 15/20\n",
      "2048/2048 [==============================] - 82s - loss: 1.9880 - acc: 0.5791 - val_loss: 3.6684 - val_acc: 0.2969\n",
      "Epoch 16/20\n",
      "2048/2048 [==============================] - 83s - loss: 1.8837 - acc: 0.6025 - val_loss: 3.6385 - val_acc: 0.3013\n",
      "Epoch 17/20\n",
      "2048/2048 [==============================] - 84s - loss: 1.8214 - acc: 0.6152 - val_loss: 3.6167 - val_acc: 0.3013\n",
      "Epoch 18/20\n",
      "2048/2048 [==============================] - 84s - loss: 1.7182 - acc: 0.6362 - val_loss: 3.5387 - val_acc: 0.3071\n",
      "Epoch 19/20\n",
      "2048/2048 [==============================] - 84s - loss: 1.6305 - acc: 0.6533 - val_loss: 3.5218 - val_acc: 0.3179\n",
      "Epoch 20/20\n",
      "2048/2048 [==============================] - 83s - loss: 1.5606 - acc: 0.6709 - val_loss: 3.4765 - val_acc: 0.3208\n"
     ]
    }
   ],
   "source": [
    "hist = tl_model.fit(X_train_data, Y_train_label, \n",
    "             batch_size=32, nb_epoch=20, \n",
    "             verbose=1, validation_split=0.5,\n",
    "             shuffle=None, class_weight=None, sample_weight=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'acc': [0.0107421875, 0.05224609375, 0.1220703125, 0.19140625, 0.24951171875, 0.294921875, 0.3369140625, 0.37890625, 0.41650390625, 0.45361328125, 0.48095703125, 0.5087890625, 0.53125, 0.56298828125, 0.5791015625, 0.6025390625, 0.615234375, 0.63623046875, 0.6533203125, 0.6708984375], 'loss': [7.3957290276885033, 5.8029070049524307, 5.0716390758752823, 4.4758717082440853, 4.028825905174017, 3.6548697166144848, 3.3783609084784985, 3.1084215752780437, 2.8757450692355633, 2.681011538952589, 2.509543327614665, 2.3504121229052544, 2.2194214202463627, 2.0847434569150209, 1.9879910089075565, 1.8836586568504572, 1.8214411623775959, 1.7181934099644423, 1.6305091688409448, 1.5606490420177579], 'val_acc': [0.0283203125, 0.0693359375, 0.10107421875, 0.13720703125, 0.16015625, 0.166015625, 0.205078125, 0.21875, 0.2216796875, 0.25048828125, 0.26416015625, 0.27294921875, 0.2822265625, 0.2880859375, 0.296875, 0.30126953125, 0.30126953125, 0.30712890625, 0.31787109375, 0.32080078125], 'val_loss': [6.709042564034462, 5.786319836974144, 5.484233058989048, 5.1035287939012051, 4.805240985006094, 4.5913661122322083, 4.4082826748490334, 4.2602869793772697, 4.1358586698770523, 4.0099372677505016, 3.9339677952229977, 3.848570890724659, 3.7713941745460033, 3.7237979881465435, 3.6683652959764004, 3.6384691558778286, 3.6167133972048759, 3.5387159958481789, 3.5217881947755814, 3.4764775447547436]}\n"
     ]
    }
   ],
   "source": [
    "print(hist.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
