{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using gpu device 0: GeForce GTX 1080 (CNMeM is disabled, cuDNN not available)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "from scipy import ndimage\n",
    "from skimage import transform\n",
    "import keras\n",
    "from keras.layers import Flatten, Dense, Input, Convolution2D, MaxPooling2D\n",
    "from keras.applications import VGG16\n",
    "from keras.models import Model\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import Callback, ModelCheckpoint, EarlyStopping\n",
    "import skimage.io as io\n",
    "\n",
    "# MEAN = np.array([123.0, 117.0, 104.0])\n",
    "MEAN = np.array([0, 0, 0])\n",
    "\n",
    "def convert_image(collect):\n",
    "#     sz = np.shape(collect)[0]\n",
    "    sz = len(collect)\n",
    "    images = np.zeros((sz, 224, 224, 3))\n",
    "    for i in range(sz):\n",
    "        img = collect[i]\n",
    "        img = transform.resize(img, (224, 224))*255\n",
    "        if (len(img.shape) != 3):\n",
    "           img = img[:,:,np.newaxis]\n",
    "        images[i] = img\n",
    "    return images\n",
    "\n",
    "sizeOfEachClass = 16\n",
    "sizeOfTestEachClass = 16\n",
    "path='/home/yiluo/Homework/253/3/256_ObjectCategories/'\n",
    "files = os.listdir(path)\n",
    "X_train, X_val, X_test = [], [], []\n",
    "Y_train, Y_val, Y_test = [], [], []\n",
    "label = 0\n",
    "for category in files:\n",
    "    sub_path = path + category\n",
    "    sub_files = os.listdir(sub_path)\n",
    "    cnt = np.shape(sub_files)[0]\n",
    "    num = 1\n",
    "    for img_nm in sub_files:\n",
    "        if img_nm[-4:] == '.jpg':\n",
    "            img_path = sub_path + '/' + img_nm\n",
    "            #img = ndimage.imread(sub_path + '/' + img_nm)\n",
    "            #img = transform.resize(img, (224, 224))*255\n",
    "            if num <= np.floor(0.8*cnt):\n",
    "                if num <= sizeOfEachClass:\n",
    "                    X_train.append(img_path)\n",
    "                    Y_train.append(label)\n",
    "            elif num <= np.floor(0.9*cnt):\n",
    "                if num <= np.floor(0.8*cnt) + sizeOfTestEachClass:\n",
    "                    X_val.append(img_path)\n",
    "                    Y_val.append(label)\n",
    "            else:\n",
    "                X_test.append(img_path)\n",
    "                Y_test.append(label)\n",
    "            num += 1\n",
    "    label += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#shuffle\n",
    "ind=range(int(len(X_train)))\n",
    "random.shuffle(ind)\n",
    "X_train = [X_train[i] for i in ind]\n",
    "Y_train = [Y_train[i] for i in ind]\n",
    "Y_train_label = np.zeros((len(Y_train), 256))\n",
    "for i in range(len(Y_train)):\n",
    "    Y_train_label[i, Y_train[i]] = 1\n",
    "    \n",
    "#validation  \n",
    "Y_val_label = np.zeros((len(Y_val), 256))\n",
    "for i in range(len(Y_val)):\n",
    "    Y_val_label[i, Y_val[i]] = 1\n",
    "    \n",
    "#test\n",
    "Y_test_label = np.zeros((len(Y_test), 256))\n",
    "for i in range(len(Y_test)):\n",
    "    Y_test_label[i, Y_test[i]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4096, 256)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(Y_train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# #Output dim for your dataset\n",
    "# output_dim = 256 #For Caltech256\n",
    "\n",
    "# tl_model = getModel( output_dim )\n",
    "# tl_model.compile(loss='categorical_crossentropy', optimizer='adadelta', metrics=['accuracy'])\n",
    "# for epoch in range(10):\n",
    "#     start = 0\n",
    "#     for batch in range(len(X_train)/64):\n",
    "#         coll=io.ImageCollection(X_train[start:start+64])\n",
    "#         images = convert_image(coll)\n",
    "#         tl_model.train_on_batch(images, Y_train_label[start:start+64, :])\n",
    "# #         tl_model.summary()\n",
    "#         start += 64\n",
    "# print 'stop here'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Data\n",
    "coll = io.ImageCollection(X_train)\n",
    "X_train_data = convert_image(coll)\n",
    "# coll_val = io.ImageCollection(X_val)\n",
    "# X_val_data = convert_image(coll_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getModel( output_dim ):\n",
    "    ''' \n",
    "        * output_dim: the number of classes (int)\n",
    "        \n",
    "        * return: compiled model (keras.engine.training.Model)\n",
    "    '''\n",
    "    vgg_model = VGG16( weights='imagenet', include_top=True )\n",
    "    layer_name = 'block5_conv3'\n",
    "    x = vgg_model.get_layer(layer_name).output\n",
    "#     x = MaxPooling2D((2, 2), strides=(2, 2), name='pool_new')(x)\n",
    "    x = Flatten(name='flatten')(x)\n",
    "#     x = Dense(2048, activation='relu', name='fc1_new')(x)\n",
    "#     x = Dense(4096, activation='relu', name='fc2_new')(x)\n",
    "    softmax_layer = Dense(256, activation='softmax')(x) #Create softmax layer taking input as vgg_out\n",
    "    #Create new transfer learning model\n",
    "    tl_model = Model( input=vgg_model.input, output=softmax_layer )\n",
    "\n",
    "    #Freeze all layers of VGG16 and Compile the model\n",
    "    #Confirm the model is appropriate\n",
    "    for l in vgg_model.layers:\n",
    "        l.trainable = False\n",
    "\n",
    "    return tl_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Model\n",
    "#Output dim for your dataset\n",
    "output_dim = 256 #For Caltech256\n",
    "tl_model = getModel( output_dim )\n",
    "# rmsprop = keras.optimizers.RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0) # error\n",
    "# sgd = keras.optimizers.SGD(lr=0.0001, momentum=0.9, decay=0.0, nesterov=True)\n",
    "tl_model.compile(loss='categorical_crossentropy', optimizer='adadelta', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_1 (InputLayer)             (None, 224, 224, 3)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "block1_conv1 (Convolution2D)     (None, 224, 224, 64)  1792        input_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "block1_conv2 (Convolution2D)     (None, 224, 224, 64)  36928       block1_conv1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block1_pool (MaxPooling2D)       (None, 112, 112, 64)  0           block1_conv2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block2_conv1 (Convolution2D)     (None, 112, 112, 128) 73856       block1_pool[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "block2_conv2 (Convolution2D)     (None, 112, 112, 128) 147584      block2_conv1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)       (None, 56, 56, 128)   0           block2_conv2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block3_conv1 (Convolution2D)     (None, 56, 56, 256)   295168      block2_pool[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "block3_conv2 (Convolution2D)     (None, 56, 56, 256)   590080      block3_conv1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block3_conv3 (Convolution2D)     (None, 56, 56, 256)   590080      block3_conv2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)       (None, 28, 28, 256)   0           block3_conv3[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block4_conv1 (Convolution2D)     (None, 28, 28, 512)   1180160     block3_pool[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "block4_conv2 (Convolution2D)     (None, 28, 28, 512)   2359808     block4_conv1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block4_conv3 (Convolution2D)     (None, 28, 28, 512)   2359808     block4_conv2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)       (None, 14, 14, 512)   0           block4_conv3[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block5_conv1 (Convolution2D)     (None, 14, 14, 512)   2359808     block4_pool[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "block5_conv2 (Convolution2D)     (None, 14, 14, 512)   2359808     block5_conv1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block5_conv3 (Convolution2D)     (None, 14, 14, 512)   2359808     block5_conv2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "flatten (Flatten)                (None, 100352)        0           block5_conv3[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 256)           25690368    flatten[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 40,405,056\n",
      "Trainable params: 25,690,368\n",
      "Non-trainable params: 14,714,688\n",
      "____________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print tl_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    samplewise_center=True)\n",
    "\n",
    "# compute quantities required for featurewise normalization\n",
    "# (std, mean, and principal components if ZCA whitening is applied)\n",
    "datagen.fit(X_train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2048 samples, validate on 2048 samples\n",
      "Epoch 1/20\n",
      "2048/2048 [==============================] - 40s - loss: 14.8057 - acc: 0.0386 - val_loss: 14.1845 - val_acc: 0.0630\n",
      "Epoch 2/20\n",
      "2048/2048 [==============================] - 41s - loss: 12.6794 - acc: 0.1909 - val_loss: 13.7882 - val_acc: 0.0928\n",
      "Epoch 3/20\n",
      "2048/2048 [==============================] - 42s - loss: 11.7421 - acc: 0.2607 - val_loss: 13.4397 - val_acc: 0.1094\n",
      "Epoch 4/20\n",
      "2048/2048 [==============================] - 42s - loss: 11.1216 - acc: 0.3022 - val_loss: 13.3828 - val_acc: 0.1094\n",
      "Epoch 5/20\n",
      "2048/2048 [==============================] - 43s - loss: 10.7051 - acc: 0.3276 - val_loss: 13.3165 - val_acc: 0.1055\n",
      "Epoch 6/20\n",
      "2048/2048 [==============================] - 42s - loss: 10.3596 - acc: 0.3525 - val_loss: 13.4339 - val_acc: 0.1074\n",
      "Epoch 7/20\n",
      "2048/2048 [==============================] - 42s - loss: 10.1223 - acc: 0.3677 - val_loss: 13.3691 - val_acc: 0.1094\n",
      "Epoch 8/20\n",
      "2048/2048 [==============================] - 42s - loss: 9.9247 - acc: 0.3809 - val_loss: 13.4220 - val_acc: 0.1108\n",
      "Epoch 9/20\n",
      "2048/2048 [==============================] - 42s - loss: 9.7909 - acc: 0.3882 - val_loss: 13.2058 - val_acc: 0.1196\n",
      "Epoch 10/20\n",
      "2048/2048 [==============================] - 42s - loss: 9.6030 - acc: 0.4014 - val_loss: 13.2501 - val_acc: 0.1187\n",
      "Epoch 11/20\n",
      "2048/2048 [==============================] - 42s - loss: 9.4702 - acc: 0.4097 - val_loss: 13.0992 - val_acc: 0.1226\n",
      "Epoch 12/20\n",
      "2048/2048 [==============================] - 43s - loss: 9.3444 - acc: 0.4170 - val_loss: 13.1055 - val_acc: 0.1216\n",
      "Epoch 13/20\n",
      "2048/2048 [==============================] - 43s - loss: 9.1883 - acc: 0.4268 - val_loss: 12.9525 - val_acc: 0.1235\n",
      "Epoch 14/20\n",
      "2048/2048 [==============================] - 43s - loss: 9.0304 - acc: 0.4375 - val_loss: 12.7439 - val_acc: 0.1338\n",
      "Epoch 15/20\n",
      "2048/2048 [==============================] - 44s - loss: 8.9443 - acc: 0.4438 - val_loss: 12.8720 - val_acc: 0.1279\n",
      "Epoch 16/20\n",
      "2048/2048 [==============================] - 44s - loss: 8.7962 - acc: 0.4512 - val_loss: 12.8239 - val_acc: 0.1328\n",
      "Epoch 17/20\n",
      "2048/2048 [==============================] - 46s - loss: 8.7371 - acc: 0.4575 - val_loss: 12.9391 - val_acc: 0.1318\n",
      "Epoch 18/20\n",
      "2048/2048 [==============================] - 44s - loss: 8.7280 - acc: 0.4585 - val_loss: 12.8872 - val_acc: 0.1333\n",
      "Epoch 19/20\n",
      "2048/2048 [==============================] - 44s - loss: 8.7280 - acc: 0.4585 - val_loss: 12.8870 - val_acc: 0.1333\n",
      "Epoch 20/20\n",
      "2048/2048 [==============================] - 42s - loss: 8.7280 - acc: 0.4585 - val_loss: 12.8867 - val_acc: 0.1333\n"
     ]
    }
   ],
   "source": [
    "hist = tl_model.fit(X_train_data, Y_train_label, \n",
    "             batch_size=32, nb_epoch=20, \n",
    "             verbose=1, validation_split=0.5,\n",
    "             shuffle=None, class_weight=None, sample_weight=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'acc': [0.03857421875, 0.19091796875, 0.2607421875, 0.30224609375, 0.32763671875, 0.3525390625, 0.36767578125, 0.380859375, 0.38818359375, 0.4013671875, 0.40966796875, 0.4169921875, 0.4267578125, 0.4375, 0.44384765625, 0.451171875, 0.45751953125, 0.45849609375, 0.45849609375, 0.45849609375], 'loss': [14.805689841508865, 12.679409220814705, 11.74211211502552, 11.121609650552273, 10.705052986741066, 10.359575062990189, 10.122346840798855, 9.9246909320354462, 9.7908512800931931, 9.6029782369732857, 9.4701602905988693, 9.3444276079535484, 9.1883098930120468, 9.0304140001535416, 8.9443164691329002, 8.7961786538362503, 8.7370554208755493, 8.7280192226171494, 8.7280116826295853, 8.7280116826295853], 'val_acc': [0.06298828125, 0.0927734375, 0.109375, 0.109375, 0.10546875, 0.107421875, 0.109375, 0.11083984375, 0.11962890625, 0.11865234375, 0.12255859375, 0.12158203125, 0.12353515625, 0.1337890625, 0.1279296875, 0.1328125, 0.1318359375, 0.13330078125, 0.13330078125, 0.13330078125], 'val_loss': [14.184478923678398, 13.788206771016121, 13.439702481031418, 13.382779970765114, 13.316545248031616, 13.433940142393112, 13.369110718369484, 13.42202465236187, 13.205832839012146, 13.250108703970909, 13.09924753010273, 13.105524212121964, 12.952533379197121, 12.74386103451252, 12.872003972530365, 12.823917001485825, 12.939060255885124, 12.887245818972588, 12.887030184268951, 12.886733204126358]}\n"
     ]
    }
   ],
   "source": [
    "print(hist.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=2, verbose=0, mode='auto'),\n",
    "    ModelCheckpoint(filepath=\"./weights.hdf5\", verbose=1, save_best_only=True)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "4096/4096 [==============================] - 40s - loss: 0.2756 - acc: 0.9353    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd614650990>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tl_model.fit(X_train_data, Y_train_label,\n",
    "#           nb_epoch=20,\n",
    "#           batch_size=16)\n",
    "\n",
    "tl_model.fit(X_train_data, Y_train_label, \n",
    "             batch_size=32, nb_epoch=1, \n",
    "             verbose=1,  \n",
    "             shuffle=None, class_weight=None, sample_weight=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2695/2695 [==============================] - 26s    \n",
      "[1.7824576142546418, 0.59962894253031884]\n"
     ]
    }
   ],
   "source": [
    "score = tl_model.evaluate(X_val_data, Y_val_label, batch_size=32, verbose=1, sample_weight=None)\n",
    "print score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# manual batch\n",
    "nb_epoch = 20\n",
    "nm_per_batch = 32\n",
    "for e in range(nb_epoch):\n",
    "    print 'Epoch', e\n",
    "    batches = 0\n",
    "    for X_batch, Y_batch in datagen.flow(X_train_data, Y_train_label, batch_size=nm_per_batch, shuffle=True):\n",
    "        loss = tl_model.train_on_batch(X_batch, Y_batch)\n",
    "#         print 'batches:', batches, ', loss:' , loss[0] , ', acc train:' , loss[1]\n",
    "#         print 'batches:', batches, 'loss:' , loss[0],\n",
    "        print 'batches:', batches,\n",
    "        \n",
    "        batches += 1\n",
    "        if batches >= len(X_train) / nm_per_batch:\n",
    "            # we need to break the loop by hand because\n",
    "            # the generator loops indefinitely\n",
    "            break\n",
    "    \n",
    "    #evaluate on validation\n",
    "    score = tl_model.evaluate(X_val_data, Y_val_label, batch_size=nm_per_batch, verbose=1, sample_weight=None)\n",
    "    print 'loss:' , loss[0] , ', acc train:' , loss[1], 'loss train: ', score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
